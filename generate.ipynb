{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Activation, Input, Reshape, UpSampling2D, ReLU, GaussianNoise\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import ops\n",
    "#from tensorflow.keras.applications import ResNet50V2 as pretrained\n",
    "from tensorflow.keras.applications import Xception as pretrained\n",
    "#from efficientnet.tfkeras import EfficientNetB0 as pretrained\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from timeout_decorator import timeout, TimeoutError\n",
    "import itertools\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_length = 512\n",
    "batch_size = 32\n",
    "n_estimators = 3\n",
    "folder = \"./faces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_init = RandomNormal(0, 0.02)\n",
    "\n",
    "\n",
    "def G_model_begin(noise_length, channel=256):\n",
    "    stddev = 0.1\n",
    "    use_bias=True\n",
    "    zin = Input((noise_length,))\n",
    "    z = Lambda(lambda x: x[:, :noise_length//2], output_shape=(noise_length//2,))(zin)\n",
    "    #z = zin\n",
    "    for i in range(8):\n",
    "        z = Dense(512, use_bias=use_bias)(z)\n",
    "        z = ReLU()(z)\n",
    "    \n",
    "    #x = Constant(4*4*channel, trainable=False)(None)\n",
    "    x = Lambda(lambda x: x[:, noise_length//2:], output_shape=(noise_length-noise_length//2,))(zin)\n",
    "    x = Dense(4*4*channel, activation=\"relu\")(x)\n",
    "    x = Reshape((4, 4, channel))(x)\n",
    "    \n",
    "    x = GaussianNoise(stddev)(x)\n",
    "    x = AdaINBlock(x,z, use_bias=use_bias)\n",
    "    x = Conv2D(channel, 3, strides=1, padding=\"same\", kernel_initializer=conv_init, use_bias=use_bias)(x)\n",
    "    x = GaussianNoise(stddev)(x)\n",
    "    x = AdaINBlock(x,z, use_bias=use_bias)\n",
    "    model = Model(inputs=zin, outputs=[x,z], name=\"generator\")\n",
    "    return model\n",
    "\n",
    "def G_model_expand(g, channel=256):\n",
    "    stddev = 0.1\n",
    "    use_bias=True\n",
    "    x, z = g.output\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(channel, 3, strides=1, padding=\"same\", kernel_initializer=conv_init, use_bias=use_bias)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = GaussianNoise(stddev)(x)\n",
    "    x = AdaINBlock(x, z, use_bias=use_bias)\n",
    "    x = Conv2D(channel, 3, strides=1, padding=\"same\", kernel_initializer=conv_init, use_bias=use_bias)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = GaussianNoise(stddev)(x)\n",
    "    x = AdaINBlock(x, z, use_bias=use_bias)\n",
    "    model = Model(inputs=g.input, outputs=[x,z])\n",
    "    return model\n",
    "\n",
    "def G_model_attach(g, channel=3):\n",
    "    x, z = g.output\n",
    "    #x = Dropout(0.1)(x)\n",
    "    x = Conv2D(channel, 1, strides=1, padding=\"same\", use_bias=False)(x)\n",
    "    outputs = Activation(\"tanh\", name=\"generator_output\")(x)\n",
    "    model = Model(inputs=g.input, outputs=outputs, name=\"generator\")\n",
    "    return model\n",
    "\n",
    "def mini_batch(g):\n",
    "    x = g.output\n",
    "    out = MinibatchStd()(x)\n",
    "    return Model(inputs=g.input, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def bin_custom(y_true, y_pred):\n",
    "    #return binary_crossentropy(y_true, y_pred) + 1.0/(K.std(y_pred)+0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = 64\n",
    "g = G_model_begin(noise_length, ch)\n",
    "#g = load_model(\"models/generator_core_8_8_20.h5\", custom_objects={\"Constant\":Constant})\n",
    "epochs = 20\n",
    "while True:\n",
    "    g_out = G_model_attach(g)\n",
    "    g_out = mini_batch(g_out)\n",
    "    height = g_out.layers[-1].output.shape[1]\n",
    "    width = g_out.layers[-1].output.shape[2]\n",
    "    ch = g_out.layers[-1].output.shape[3]\n",
    "    d = D_model(Height=height, Width=width, n_estimators=n_estimators, channel=ch)\n",
    "    c = Combined_model(g=g_out, d=d)\n",
    "\n",
    "    d_opt = Adam(lr=1e-4, beta_1=0.5, beta_2=0.9)\n",
    "    g_opt = Adam(lr=1e-4, beta_1=0.5, beta_2=0.9)\n",
    "    \n",
    "    g_out.compile(loss='binary_crossentropy', optimizer=g_opt)\n",
    "    d.trainable = False\n",
    "    for layer in d.layers:\n",
    "        layer.trainable = False\n",
    "    c.compile(loss='binary_crossentropy', optimizer=g_opt)\n",
    "    \n",
    "    d.trainable = True\n",
    "    for layer in d.layers:\n",
    "        layer.trainable = True\n",
    "    d.compile(loss='binary_crossentropy', optimizer=d_opt)\n",
    "\n",
    "    g_losses=[]\n",
    "    d_losses=[]\n",
    "    \n",
    "\n",
    "    X_train = [{\"filepath\":os.path.join(folder,path), \"height\":height, \"width\":width} for path in os.listdir(folder)]    \n",
    "    with Pool() as p:\n",
    "        imap = p.imap(read_file_wrap, X_train)\n",
    "        X_train = list(tqdm(imap,total=len(X_train)))\n",
    "\n",
    "    X_train = [img for img in X_train if img is not None]\n",
    "    \n",
    "    row = 3\n",
    "    col = 4\n",
    "    fig = plt.figure(figsize=(col*3, row*3))\n",
    "    plt.suptitle(\"train shape: {0} * {1}\".format(width,height), fontsize=20)\n",
    "    for i in range(row * col):\n",
    "        plt.subplot(row, col, i+1)\n",
    "        img = random.choice(X_train)\n",
    "        plt.imshow(img.astype(np.uint8))\n",
    "        plt.axis('off')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "        _g_losses = []\n",
    "        _d_losses = []\n",
    "        np.random.shuffle(X_train)\n",
    "        for ite in tqdm(range(1, len(X_train)//batch_size+1)):\n",
    "            # Discremenator training\n",
    "            y = X_train[ite * batch_size: (ite+1) * batch_size]\n",
    "            y += [cv2.flip(img, 1) for img in y]\n",
    "            y = np.asarray(y)\n",
    "            y = (y.astype(np.float32)-127.5)/127.5\n",
    "            y = MinibatchStd()(y)\n",
    "            input_noise = np.random.uniform(-1, 1, size=(y.shape[0], noise_length))\n",
    "            g_output = g_out.predict(input_noise, verbose=0)\n",
    "            _X_train = np.concatenate((y, g_output))\n",
    "            _Y_train = [np.array([1.0] * y.shape[0] + [0.0] * g_output.shape[0])] * n_estimators\n",
    "            d_loss = d.train_on_batch(_X_train, _Y_train)\n",
    "            _d_losses.append(d_loss)\n",
    "            # Generator training\n",
    "            input_noise = np.random.uniform(-1, 1, size=(batch_size*5, noise_length))\n",
    "            g_loss = c.train_on_batch(input_noise, [[1.0] * batch_size*5] * n_estimators)\n",
    "            _g_losses.append(g_loss)\n",
    "    \n",
    "        if epoch%5==1 or epoch==epochs:\n",
    "            g_out.save(\"./models/generator_{0}_{1}_{2}.h5\".format(width, height, epoch))\n",
    "            g.save(\"./models/generator_core_{0}_{1}_{2}.h5\".format(width, height, epoch))\n",
    "            d.save(\"./models/discriminator_{0}_{1}_{2}.h5\".format(width, height, epoch))\n",
    "        g_losses.append(np.mean(_g_losses))\n",
    "        d_losses.append(np.mean(_d_losses))\n",
    "        print(\"g loss = {0}, d loss = {1}\".format(g_losses[-1], d_losses[-1]))\n",
    "        visualize(g_out, d, epoch, row=1, col=3, save=\"output_images/{0}_{1}_{2}epoch{3}.png\".format(width, height, ch, epoch))\n",
    "    \n",
    "    epochs += 20\n",
    "    #for layer in g.layers[20:]:\n",
    "        #layer.trainable=False\n",
    "    g = G_model_expand(g, ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.uniform(-1, 1, size=(1, noise_length))\n",
    "plt.imshow((g_out.predict(noise, verbose=0)[0]*127.5+127.5).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(g,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
