{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, Input, BatchNormalization, Reshape, UpSampling2D, PReLU, ReLU, LeakyReLU, Lambda, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "#from tensorflow.keras.applications import ResNet50V2 as pretrained\n",
    "from tensorflow.keras.applications import Xception as pretrained\n",
    "#from efficientnet.tfkeras import EfficientNetB0 as pretrained\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from multiprocessing import Pool\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from timeout_decorator import timeout, TimeoutError\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_length = 128\n",
    "width = 256\n",
    "height = 256\n",
    "epochs = 600\n",
    "batch_size = 64\n",
    "n_estimators = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "conv_init = RandomNormal(0, 0.02)\n",
    "\n",
    "def G_model(Height, Width, channel=3):\n",
    "\n",
    "    inputs = Input((noise_length,))\n",
    "    x = Dense((Height//16) * (Width//16) * 512)(inputs)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Reshape(((Height//16) , (Width//16), 512))(x)\n",
    "    x = Conv2D(1024, 1, strides=1, padding=\"same\",\n",
    "               kernel_initializer=conv_init)(x)\n",
    "    x = SubpixelConv2D(x)(x)  # 8x8x256\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Conv2D(512, 1, strides=1, padding=\"same\",\n",
    "               kernel_initializer=conv_init)(x)\n",
    "    x = SubpixelConv2D(x)(x)  # 16x16x128\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Conv2D(256, 1, strides=1, padding=\"same\",\n",
    "               kernel_initializer=conv_init)(x)\n",
    "    x = SubpixelConv2D(x)(x)  # 32x32x64\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Conv2D(12, 1, strides=1, padding=\"same\",\n",
    "               kernel_initializer=conv_init)(x)\n",
    "    x = SubpixelConv2D(x)(x)  # 64x64x3\n",
    "    outputs = Activation(\"tanh\", name=\"generator_output\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='generator')\n",
    "    return model\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def G_model(Height, Width, channel=3):\n",
    "\n",
    "    zin = Input((noise_length,))\n",
    "    z = zin\n",
    "    for i in range(8):\n",
    "        z = Dense(512, activation=\"relu\")(z)\n",
    "    \n",
    "    c = tf.constant([[1]])\n",
    "    x = Dense(4*4*512)(c)\n",
    "    x = Reshape((4, 4, 512))(x)\n",
    "    \n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    uints, shape = parseshape(x)\n",
    "    style = Dense(uints)(z)\n",
    "    style = Reshape(shape)(style)\n",
    "    x = AdaIN()([x, style])\n",
    "    x = Conv2D(256, 3, strides=1, padding=\"same\")(x)\n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    uints, shape = parseshape(x)\n",
    "    style = Dense(uints)(z)\n",
    "    style = Reshape(shape)(style)\n",
    "    x = AdaIN()([x, style])\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(128, 3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    uints, shape = parseshape(x)\n",
    "    style = Dense(uints)(z)\n",
    "    style = Reshape(shape)(style)\n",
    "    x = AdaIN()([x, style])\n",
    "    x = Conv2D(128, 3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    uints, shape = parseshape(x)\n",
    "    style = Dense(uints)(z)\n",
    "    style = Reshape(shape)(style)\n",
    "    x = AdaIN()([x, style])\n",
    "    \n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(64, 3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    uints, shape = parseshape(x)\n",
    "    style = Dense(uints)(z)\n",
    "    style = Reshape(shape)(style)\n",
    "    x = AdaIN()([x, style])\n",
    "    x = Conv2D(64, 3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    uints, shape = parseshape(x)\n",
    "    style = Dense(uints)(z)\n",
    "    style = Reshape(shape)(style)\n",
    "    x = AdaIN()([x, style])\n",
    "    \n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(32, 3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    uints, shape = parseshape(x)\n",
    "    style = Dense(uints)(z)\n",
    "    style = Reshape(shape)(style)\n",
    "    x = AdaIN()([x, style])\n",
    "    x = Conv2D(32, 3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    uints, shape = parseshape(x)\n",
    "    style = Dense(uints)(z)\n",
    "    style = Reshape(shape)(style)\n",
    "    x = AdaIN()([x, style])\n",
    "    \n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(16, 3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    uints, shape = parseshape(x)\n",
    "    style = Dense(uints)(z)\n",
    "    style = Reshape(shape)(style)\n",
    "    x = AdaIN()([x, style])\n",
    "    x = Conv2D(16, 3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    uints, shape = parseshape(x)\n",
    "    style = Dense(uints)(z)\n",
    "    style = Reshape(shape)(style)\n",
    "    x = AdaIN()([x, style])\n",
    "    \n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(8, 3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    uints, shape = parseshape(x)\n",
    "    style = Dense(uints)(z)\n",
    "    style = Reshape(shape)(style)\n",
    "    x = AdaIN()([x, style])\n",
    "    x = Conv2D(8, 3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    uints, shape = parseshape(x)\n",
    "    style = Dense(uints)(z)\n",
    "    style = Reshape(shape)(style)\n",
    "    x = AdaIN()([x, style])\n",
    "    \n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(4, 3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    uints, shape = parseshape(x)\n",
    "    style = Dense(uints)(z)\n",
    "    style = Reshape(shape)(style)\n",
    "    x = AdaIN()([x, style])\n",
    "    x = Conv2D(3, 3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = GaussianNoise(0.1)(x)\n",
    "    uints, shape = parseshape(x)\n",
    "    style = Dense(uints)(z)\n",
    "    style = Reshape(shape)(style)\n",
    "    x = AdaIN()([x, style])\n",
    "\n",
    "    outputs = Activation(\"tanh\", name=\"generator_output\")(x)\n",
    "    model = Model(inputs=zin, outputs=outputs, name=\"generator\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_model_core(Height, Width, channel=3):\n",
    "    inputs = Input((Height, Width, channel))\n",
    "    x = Conv2D(64, (5, 5), padding=\"same\", strides=(2,2))(inputs)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Conv2D(128, (5, 5), padding=\"same\", strides=(2,2))(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Conv2D(256, (5, 5), padding=\"same\", strides=(2,2))(x)\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5) (x)\n",
    "    x = Dense(1024)(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def D_model(Height, Width, channel=3, n_estimators=3):\n",
    "    inputs = Input((Height, Width, channel))\n",
    "    outputs = []\n",
    "    for i in range(n_estimators):\n",
    "        outputs.append(D_model_core(Height, Width, channel)(inputs))\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"discriminator\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = G_model(Height=height, Width=width)\n",
    "d = D_model(Height=height, Width=width, n_estimators=n_estimators)\n",
    "#g = load_model(\"models/generator_256_256_255.h5\")\n",
    "#d = load_model(\"models/discriminator_256_256_255.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Combined_model(g=g, d=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "d_opt = Adam(lr=0.0002, beta_1=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.compile(loss='binary_crossentropy', optimizer='SGD')\n",
    "d.trainable = False\n",
    "for layer in d.layers:\n",
    "    layer.trainable = False\n",
    "c.compile(loss='binary_crossentropy', optimizer=g_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.trainable = True\n",
    "for layer in d.layers:\n",
    "    layer.trainable = True\n",
    "d.compile(loss='binary_crossentropy', optimizer=d_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_model(c, show_shapes=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    img = cv2.imread(filepath)\n",
    "    if img is None:\n",
    "        print(\"no such file {0}\".format(filepath))\n",
    "        return\n",
    "    _width, _height, _ = img.shape\n",
    "    img = cv2.resize(img, (width,height))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=\"./faces\"\n",
    "\n",
    "X_train = [os.path.join(folder,path) for path in os.listdir(folder)]\n",
    "with Pool() as p:\n",
    "    imap = p.imap(read_file, X_train)\n",
    "    X_train = list(tqdm(imap,total=len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 7\n",
    "col = 8\n",
    "plt.figure(figsize=(col*3, row*3))\n",
    "plt.suptitle(\"train size: {0}\".format(len(X_train)), fontsize=20)\n",
    "for i in range(row * col):\n",
    "    plt.subplot(row, col, i+1)\n",
    "    img = random.choice(X_train)\n",
    "    plt.imshow(img.astype(np.uint8))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_losses = []\n",
    "d_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    _g_losses = []\n",
    "    _d_losses = []\n",
    "    np.random.shuffle(X_train)\n",
    "    for ite in tqdm(range(1, len(X_train)//batch_size+1)):\n",
    "        # Discremenator training\n",
    "        y = X_train[ite * batch_size: (ite+1) * batch_size]\n",
    "        y += [cv2.flip(img, 1) for img in y]\n",
    "        y = np.asarray(y)\n",
    "        y = (y.astype(np.float32)-127.5)/127.5\n",
    "        input_noise = np.random.uniform(-1, 1, size=(y.shape[0], noise_length))\n",
    "        g_output = g.predict(input_noise, verbose=0)\n",
    "        _X_train = np.concatenate((y, g_output))\n",
    "        _Y_train = [np.array([1] * y.shape[0] + [0] * g_output.shape[0])] * n_estimators\n",
    "        d_loss = d.train_on_batch(_X_train, _Y_train)\n",
    "        _d_losses.append(d_loss)\n",
    "        # Generator training\n",
    "        #if epoch%3==1:\n",
    "        input_noise = np.random.uniform(-1, 1, size=(batch_size, noise_length))\n",
    "        g_loss = c.train_on_batch(input_noise, [[1] * batch_size] * n_estimators)\n",
    "        _g_losses.append(g_loss)\n",
    "    \n",
    "    if epoch%5==1:\n",
    "        g.save(\"./models/generator_{0}_{1}_{2}T3.h5\".format(width,height,epoch))\n",
    "        d.save(\"./models/discriminator_{0}_{1}_{2}T3.h5\".format(width,height,epoch))\n",
    "    g_losses.append(np.mean(_g_losses))\n",
    "    d_losses.append(np.mean(_d_losses))\n",
    "    print(\"g loss = {0}, d loss = {1}\".format(g_losses[-1],d_losses[-1]))\n",
    "    visualize(g,d,epoch,row=1,col=3,save=\"output_images/epoch{}.png\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.uniform(-1, 1, size=(1, noise_length))\n",
    "plt.imshow((g.predict(noise, verbose=0)[0]*127.5+127.5).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(g,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
